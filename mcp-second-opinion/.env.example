# MCP Second Opinion Server Environment Variables (EXAMPLE)
#
# Copy this file to .env and fill in your actual values:
#   cp .env.example .env
#   nano .env  # edit with your API keys
#
# You need at least ONE API key (Gemini or OpenAI) for the server to work.
# For multi-model comparison, configure both.

# =============================================================================
# Gemini API (Google)
# =============================================================================
# Get your Gemini API key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# =============================================================================
# OpenAI API (GPT-4o, Codex, o1/o3 reasoning models)
# =============================================================================
# Get your OpenAI API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Available models:
#   - gpt-4o, gpt-4o-mini: Fast multimodal models
#   - gpt-4-turbo: Complex reasoning
#   - gpt-5.1-codex-max: Most capable for complex coding (Responses API)
#   - gpt-5.1-codex-mini: Cost-effective coding (Responses API)
#   - o3: Advanced reasoning (Responses API)
#   - o1, o1-mini: Reasoning models

# =============================================================================
# Server configuration
# =============================================================================
MCP_SERVER_HOST=127.0.0.1
MCP_SERVER_PORT=8080

# Context caching (reduces cost by 90% for repeated prompts - Gemini only)
ENABLE_CONTEXT_CACHING=true
CACHE_TTL_MINUTES=60
